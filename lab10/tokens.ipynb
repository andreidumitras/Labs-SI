{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e8b3d3",
   "metadata": {},
   "source": [
    "# Introducere\n",
    "blah\n",
    "### Opera lui Shakespeare concatenata intr-un singur fisier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descarcati fisierul input.txt care contine textul lui Shakespeare\n",
    "# Comanda PowerShell/Linux\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4652ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# deschide fisierul input.txt pentru citire, cu un encoding de UTF-8\n",
    "# citeste si salveaza tot continutul fisierului intr-o variabila (text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ad863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# inspecteaza lungimea textului, afisand numarul de caractere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# afiseaza primele 250 de caractere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# creaza alfabetul corespunzator textului, prin alcatuirea unei liste care sa contina fiecare caracter o data.\n",
    "# Alfabetul trebuie ordonat alfapebtic. \n",
    "# Afiseaza apoi lungimea acestuia pe ecran.\n",
    "#   exemplu: [' ', a, b, c, ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a701e",
   "metadata": {},
   "source": [
    "# Strategie de Tokenizare a textului\n",
    "Tokenizarea presupune stabilirea unei coresponente intre text, si valori numerice ce pot fi procesare de catre algoritm. Token-ii reprezinta acele valori intregi care cuantifica (stabilesc o valoare numerica) in mod specific unui cuvant, a unui caracter, sau a unei expresii, in functie de contextul dat. De exemplu, Google foloseste ```SantancePeace```, o metoda care face corespondenta la nivel de bucati de cuvant, sau a unui cuvant intreg (depunde cum nimereste). OpenAI foloseste ```tiktoken```, o alta metoda asemanatoare cu Google. Astfel, pentru input-uri imense, se optimizeaza cat de cat numarul de parametri de intrare, iar faptul ca se recurge la nivel de subcuvant, este cel mai probabil datorita  gramaticii.\n",
    "\n",
    "Ex: \"doggy\" = dog (cuvant radacina) + gy (sufix diminutiv) --> tot despre caine e vorba, insa despre unul mai mic.\n",
    "Astfel cuvantul \"doggy\" => [30146(dog), 4544(gy)]\n",
    "\n",
    "Valorile intregi, corespund dimensiunii vocabularului (sau in cazul nostru, al alfabetului) din structura interna. OpenAI are un vocabular de approximativ 50000 de token-uri, dupa cum se poate vedea in exemplul dat.\n",
    "\n",
    "Noi insa, vom construi aici (pentru simplitate) un model de limbaj la nivel de caracter (Character-Level Language Model), care va converti fiecare caracter in numere intregi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# construiti o mapare/corespondenta (dictionary/lookuptable) intre fiecare caracter din alfabet si un index numeric.\n",
    "#   exemplu: {\n",
    "#      ' ': 0,\n",
    "#      'a': 1,\n",
    "#      'b': 2,\n",
    "#      'c': 3,\n",
    "#      ...\n",
    "#   }\n",
    "\n",
    "\n",
    "# construiti in acelasi mod o mapare inversa, intre valoarea numerica si caracter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# construiti encoder-ul.\n",
    "# definiti o fuctie lambda (```lambda arguments: expression```) care sa primeasca un sir de caractere si sa returneze lista de indici corespunzatori fiecarui caracter.\n",
    "#   exemplu: encode('abc') -> [1, 2, 3]\n",
    "\n",
    "\n",
    "# realizati in acelasi mod decoder-ul. (tot o functie lambda)\n",
    "# acesta va primi o lista de indici, va gasi caracterul corespunzator fiecarui indice si va construi o lista.\n",
    "# lista aceasta de caractere va fi concatenata si returnata ca rezultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9b8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testati encoder-ul si decoder-ul pe urmatorul text: \"To be or not to be...\".\n",
    "# afisati rezultatul encoder-ului:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16614cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodati urmatorul vector: [19, 19, 1, 10, 28]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae534036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# compara rezultatul encoder-ului tau cu cel folosit de GPT-2\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b615db0f",
   "metadata": {},
   "source": [
    "Vom tokeniza tot textul primit ca input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# TODO:\n",
    "# encodeaza textul citit folosind metoda noastra de character-level encoding, salvandu-l intr-o variabila\n",
    "\n",
    "\n",
    "# creaza un tensor cu acest vector\n",
    "\n",
    "\n",
    "# afiseaza dimensiunea tensorului si tipul elementelor ale acestuia (.shape, .dtype)\n",
    "\n",
    "# afiseaza primele 100 elemente ale tensorului\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
