{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC5Yx6mnQNpI",
        "papermill": {
          "duration": 0.013638,
          "end_time": "2023-08-18T05:24:44.088208",
          "exception": false,
          "start_time": "2023-08-18T05:24:44.07457",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src=\"https://github.com/FarzadNekouee/Keras-CIFAR10-CNN-Model/blob/master/image.png?raw=true\" width=\"1800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM5ijDyVQNpJ",
        "papermill": {
          "duration": 0.012214,
          "end_time": "2023-08-18T05:24:44.112831",
          "exception": false,
          "start_time": "2023-08-18T05:24:44.100617",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The __CIFAR-10__ dataset is a well-established benchmark in the field of machine learning, specifically designed for __image classification__. Comprising __60,000 color images__, each of __size 32x32 pixels__, the dataset is segmented into __10 distinct classes__, each representing a different object or creature. The classes encompass the following:\n",
        "\n",
        "- Airplane\n",
        "- Automobile\n",
        "- Bird\n",
        "- Cat\n",
        "- Deer\n",
        "- Dog\n",
        "- Frog\n",
        "- Horse\n",
        "- Ship\n",
        "- Truck\n",
        "\n",
        "Each class contains an equal distribution, boasting 6,000 images. From the total image count, 50,000 are designated for training while the remaining 10,000 are set aside for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LgDv8AuQNpN",
        "papermill": {
          "duration": 0.012218,
          "end_time": "2023-08-18T05:24:44.213304",
          "exception": false,
          "start_time": "2023-08-18T05:24:44.201086",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "First, we're importing all the necessary libraries to kick off our project. We'll be relying on __TensorFlow__ and __Keras__ to handle the image data, craft our model, and optimize it for best performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:19:41.105864Z",
          "iopub.status.busy": "2023-08-19T07:19:41.105201Z",
          "iopub.status.idle": "2023-08-19T07:19:51.482223Z",
          "shell.execute_reply": "2023-08-19T07:19:51.481243Z",
          "shell.execute_reply.started": "2023-08-19T07:19:41.105829Z"
        },
        "id": "o8pJgXXzQNpN",
        "papermill": {
          "duration": 9.462913,
          "end_time": "2023-08-18T05:24:53.688481",
          "exception": false,
          "start_time": "2023-08-18T05:24:44.225568",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D\n",
        "from keras.layers import Dropout, Flatten, BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN2SL9gtQNpP",
        "papermill": {
          "duration": 0.01213,
          "end_time": "2023-08-18T05:24:53.713709",
          "exception": false,
          "start_time": "2023-08-18T05:24:53.701579",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        " # Data Preparation and Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2dgLgklQNpP",
        "papermill": {
          "duration": 0.011995,
          "end_time": "2023-08-18T05:24:53.738391",
          "exception": false,
          "start_time": "2023-08-18T05:24:53.726396",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's download the __CIFAR-10__ dataset from Keras library, and then split original training data to training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:19:51.484377Z",
          "iopub.status.busy": "2023-08-19T07:19:51.483671Z",
          "iopub.status.idle": "2023-08-19T07:19:56.285269Z",
          "shell.execute_reply": "2023-08-19T07:19:56.284284Z",
          "shell.execute_reply.started": "2023-08-19T07:19:51.48435Z"
        },
        "id": "VZaXoFAjQNpQ",
        "papermill": {
          "duration": 6.532997,
          "end_time": "2023-08-18T05:25:00.284306",
          "exception": false,
          "start_time": "2023-08-18T05:24:53.751309",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQAFMvyrQNpR",
        "papermill": {
          "duration": 0.015238,
          "end_time": "2023-08-18T05:25:00.448485",
          "exception": false,
          "start_time": "2023-08-18T05:25:00.433247",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "  Now, we're printing out the dimensions of our training, validation, and test datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:19:56.351647Z",
          "iopub.status.busy": "2023-08-19T07:19:56.350631Z",
          "iopub.status.idle": "2023-08-19T07:19:56.360302Z",
          "shell.execute_reply": "2023-08-19T07:19:56.359014Z",
          "shell.execute_reply.started": "2023-08-19T07:19:56.351612Z"
        },
        "id": "WQ2xwu0tQNpR",
        "papermill": {
          "duration": 0.025259,
          "end_time": "2023-08-18T05:25:00.488776",
          "exception": false,
          "start_time": "2023-08-18T05:25:00.463517",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print('Train Images Shape:      ', X_train.shape)\n",
        "print('Train Labels Shape:      ', y_train.shape)\n",
        "\n",
        "print('\\nValidation Images Shape: ', X_valid.shape)\n",
        "print('Validation Labels Shape: ', y_valid.shape)\n",
        "\n",
        "print('\\nTest Images Shape:       ', X_test.shape)\n",
        "print('Test Labels Shape:       ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In8pw6ZwQNpS",
        "papermill": {
          "duration": 0.015838,
          "end_time": "2023-08-18T05:25:00.51997",
          "exception": false,
          "start_time": "2023-08-18T05:25:00.504132",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Afterward, let's take an overview of the __CIFAR-10__ dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:19:56.362558Z",
          "iopub.status.busy": "2023-08-19T07:19:56.362001Z",
          "iopub.status.idle": "2023-08-19T07:19:59.375297Z",
          "shell.execute_reply": "2023-08-19T07:19:59.374426Z",
          "shell.execute_reply.started": "2023-08-19T07:19:56.362523Z"
        },
        "id": "DzXjE2jbQNpS",
        "papermill": {
          "duration": 2.983705,
          "end_time": "2023-08-18T05:25:03.518975",
          "exception": false,
          "start_time": "2023-08-18T05:25:00.53527",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# CIFAR-10 classes\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Create a new figure\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "# Loop over the first 25 images\n",
        "for i in range(64):\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(8, 8, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(X_train[i])\n",
        "\n",
        "    # Set the label as the title\n",
        "    plt.title(class_names[y_train[i][0]], fontsize=12)\n",
        "\n",
        "# Display the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD-TO_aOQNpS",
        "papermill": {
          "duration": 0.020794,
          "end_time": "2023-08-18T05:25:03.561135",
          "exception": false,
          "start_time": "2023-08-18T05:25:03.540341",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 3: Data Preprocessing\n",
        "In the **Data Preprocessing** phase, we undertake essential preparatory measures to ensure our dataset is aptly primed for the modeling process:\n",
        "\n",
        "1. **Normalization of Image Data**\n",
        "\n",
        "2. **One-Hot Encoding of Labels**\n",
        "\n",
        "3. **Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWhh_0tUQNpS",
        "papermill": {
          "duration": 0.020466,
          "end_time": "2023-08-18T05:25:03.684588",
          "exception": false,
          "start_time": "2023-08-18T05:25:03.664122",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "   \n",
        "Convert the pixel values data type to __float32__ type, and then normalizes them by subtracting the mean and dividing by the standard deviation of the training set, enhancing the model's training efficiency and effectiveness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:19:59.376661Z",
          "iopub.status.busy": "2023-08-19T07:19:59.376334Z",
          "iopub.status.idle": "2023-08-19T07:20:00.210711Z",
          "shell.execute_reply": "2023-08-19T07:20:00.209663Z",
          "shell.execute_reply.started": "2023-08-19T07:19:59.376631Z"
        },
        "id": "9BkKlWHtQNpT",
        "papermill": {
          "duration": 0.867164,
          "end_time": "2023-08-18T05:25:04.57287",
          "exception": false,
          "start_time": "2023-08-18T05:25:03.705706",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Convert pixel values data type to float32\n",
        "X_train = X_train.astype('float32')\n",
        "X_test  = X_test.astype('float32')\n",
        "X_valid = X_valid.astype('float32')\n",
        "\n",
        "# Calculate the mean and standard deviation of the training images\n",
        "mean = np.mean(X_train)\n",
        "std  = np.std(X_train)\n",
        "\n",
        "# Normalize the data\n",
        "# The tiny value 1e-7 is added to prevent division by zero\n",
        "X_train = (X_train-mean)/(std+1e-7)\n",
        "X_test  = (X_test-mean) /(std+1e-7)\n",
        "X_valid = (X_valid-mean)/(std+1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSd2q_CXQNpT",
        "papermill": {
          "duration": 0.020419,
          "end_time": "2023-08-18T05:25:04.658559",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.63814",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Convert the class labels to one-hot vectors to transform the categorical labels into a format suitable for multi-class classification by neural networks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:20:00.212808Z",
          "iopub.status.busy": "2023-08-19T07:20:00.212404Z",
          "iopub.status.idle": "2023-08-19T07:20:00.220322Z",
          "shell.execute_reply": "2023-08-19T07:20:00.219163Z",
          "shell.execute_reply.started": "2023-08-19T07:20:00.212769Z"
        },
        "id": "DQtjOilWQNpT",
        "papermill": {
          "duration": 0.029784,
          "end_time": "2023-08-18T05:25:04.708587",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.678803",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_valid = to_categorical(y_valid, 10)\n",
        "y_test  = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpXBJy_DQNpT",
        "papermill": {
          "duration": 0.020092,
          "end_time": "2023-08-18T05:25:04.789722",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.76963",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Finally, implement data augmentation to artificially expand the size of the training set by creating modified versions of images in the dataset. This helps improve the model's ability to generalize, thereby reducing overfitting. Data augmentation techniques such as rotations, shifts, flips, shearing, and intensity changes introduce small variations to the existing images, creating a broader set of training samples to learn from.\n",
        "\n",
        "The choice of data augmentation techniques often depends on the specific characteristics of the dataset and the problem at hand. The __CIFAR-10__ dataset comprises small color images of objects from 10 different classes. Given the nature of these images, some augmentation techniques are more applicable than others:\n",
        "\n",
        "* __Rotation__: A small degree of rotation can help the model become invariant to the orientation of the object. The `rotation_range=15` means the image could be rotated randomly within -15 to 15 degrees. However, large rotations could be harmful since the CIFAR-10 images are relatively small and a big rotation might put the object outside of the image.\n",
        "\n",
        "    \n",
        "* __Width and Height shift__: Small shifts can help the model become invariant to the position of the object in the image. Here, `width_shift_range=0.12` and `height_shift_range=0.12` mean the image could be moved horizontally or vertically by up to 12% of its width or height respectively. Again, since the images are small, large shifts might put the object outside of the image.\n",
        "\n",
        "    \n",
        "* __Horizontal Flip__: A horizontal flip is a sensible choice for this dataset because for many images, the object of interest remains the same when flipped horizontally (for example, a flipped car is still a car).\n",
        "\n",
        "    \n",
        "* __Zoom__: Small zooming in by up to 10% (`zoom_range=0.1`) can also help the model generalize better. However, excessive zooming might lead to significant information loss.\n",
        "\n",
        "    \n",
        "* __Brightness Range__: Changing brightness can simulate various lighting conditions. With `brightness_range=[0.9,1.1]`, the brightness of the image is randomly changed to a value between 90% and 110% of the original brightness.\n",
        "\n",
        "    \n",
        "* __Shear Intensity__: With `shear_range=10`, a shear intensity within the range of -10 to +10 degrees is applied. This transformation slants the shape of the image, helping the model to recognize objects in different perspectives.\n",
        "\n",
        "    \n",
        "* __Channel Shift Intensity__: With `channel_shift_range=0.1`, the intensities of the RGB channels are randomly shifted by up to 10% of their full scale. This can help the model handle different lighting conditions and color variations.\n",
        "\n",
        "While some augmentation techniques like vertical flips and color jittering may not be appropriate for all classes in the __CIFAR-10__ dataset, the chosen techniques are expected to help improve the robustness and generalization capability of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:20:00.225692Z",
          "iopub.status.busy": "2023-08-19T07:20:00.225406Z",
          "iopub.status.idle": "2023-08-19T07:20:00.232535Z",
          "shell.execute_reply": "2023-08-19T07:20:00.231609Z",
          "shell.execute_reply.started": "2023-08-19T07:20:00.225667Z"
        },
        "id": "-pacZCJHQNpU",
        "papermill": {
          "duration": 0.029903,
          "end_time": "2023-08-18T05:25:04.840052",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.810149",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    # Rotate images randomly by up to 15 degrees\n",
        "    rotation_range=15,\n",
        "\n",
        "    # Shift images horizontally by up to 12% of their width\n",
        "    width_shift_range=0.12,\n",
        "\n",
        "    # Shift images vertically by up to 12% of their height\n",
        "    height_shift_range=0.12,\n",
        "\n",
        "    # Randomly flip images horizontally\n",
        "    horizontal_flip=True,\n",
        "\n",
        "    # Zoom images in by up to 10%\n",
        "    zoom_range=0.1,\n",
        "\n",
        "    # Change brightness by up to 10%\n",
        "    brightness_range=[0.9,1.1],\n",
        "\n",
        "    # Shear intensity (shear angle in counter-clockwise direction in degrees)\n",
        "    shear_range=10,\n",
        "\n",
        "    # Channel shift intensity\n",
        "    channel_shift_range=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Q3dNi_QNpU",
        "papermill": {
          "duration": 0.020151,
          "end_time": "2023-08-18T05:25:04.880761",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.86061",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "   When running the above code, we are setting up a pipeline for preprocessing the images during model training. The generator applies a series of random transformations (specified by the parameters) to the images each time they are loaded into the model for training. Each time an epoch is run during model training, these random transformations will create different variations of the original images. These changes are made __on-the-fly__ and don't modify our original dataset.      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbRoS5NNQNpU",
        "papermill": {
          "duration": 0.020563,
          "end_time": "2023-08-18T05:25:04.922178",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.901615",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 4: Define CNN Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLXZ0bpNQNpU",
        "papermill": {
          "duration": 0.02114,
          "end_time": "2023-08-18T05:25:04.964436",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.943296",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Another model architecture that will be defined is inspired from the __VGG16__ network. It contains multiple convolutional layers followed by max-pooling and dropout layers, and finally a fully connected layer for classification. While not adopting advanced modules like residuals or inceptions, this design is simpler, ensuring fewer parameters and a more straightforward architecture, making it more computationally efficient.\n",
        "\n",
        "Here is a brief explanation of the architecture:\n",
        "\n",
        "- The network begins with __a pair of Conv2D layers__, each with __32 filters of size 3x3__. This is followed by a __Batch Normalization__ layer which accelerates training and provides some level of __regularization__, helping to prevent overfitting.\n",
        "\n",
        "    \n",
        "- The pairs of Conv2D layers are followed by a __MaxPooling2D layer__, which reduces the spatial dimensions (height and width), effectively providing a form of translation invariance and reducing computational complexity. This is followed by a __Dropout layer__ that randomly sets a fraction (0.2 for the first dropout layer) of the input units to 0 at each update during training, helping to prevent overfitting.\n",
        "\n",
        "    \n",
        "- This pattern of two Conv2D layers, followed by a Batch Normalization layer, a MaxPooling2D layer, and a Dropout layer, repeats three more times. The number of filters in the Conv2D layers doubles with each repetition, starting from 32 and going up to 64, 128, and then 256. This increasing pattern helps the network to learn more complex features at each level. The dropout rate also increases at each step, from 0.2 to 0.5.\n",
        "\n",
        "    \n",
        "- After the convolutional and pooling layers, a __Flatten layer__ is used to convert the 2D outputs of the preceding layer into a 1D vector.\n",
        "\n",
        "    \n",
        "- Finally, a __Dense (or fully connected) layer__ is used for classification. It has 10 units, each representing one of the 10 classes of the CIFAR-10 dataset, and a __softmax activation function__ is used to convert the outputs to probability scores for each class.\n",
        "\n",
        "    \n",
        "This architecture leverages the strengths of deep CNNs to learn hierarchical features from the CIFAR-10 images. Regularization techniques such as __L2 regularization__, __Dropout__, and __Batch Normalization__ are also used to combat overfitting. While being inspired by VGG16, the model remains simpler and does not incorporate the more advanced features of recent architectures, focusing instead on efficiency and simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:20:00.234403Z",
          "iopub.status.busy": "2023-08-19T07:20:00.233974Z",
          "iopub.status.idle": "2023-08-19T07:20:05.341788Z",
          "shell.execute_reply": "2023-08-19T07:20:05.340717Z",
          "shell.execute_reply.started": "2023-08-19T07:20:00.234372Z"
        },
        "id": "3BjW_sksQNpU",
        "papermill": {
          "duration": 4.871222,
          "end_time": "2023-08-18T05:25:09.85613",
          "exception": false,
          "start_time": "2023-08-18T05:25:04.984908",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Set the weight decay value for L2 regularization\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# Add the first convolutional layer with 32 filters of size 3x3\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay),\n",
        "                 input_shape=X_train.shape[1:]))\n",
        "# Add batch normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the second convolutional layer similar to the first\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the first max pooling layer with pool size of 2x2\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Add dropout layer with 0.2 dropout rate\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "# Add the third and fourth convolutional layers with 64 filters\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the second max pooling layer and increase dropout rate to 0.3\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.3))\n",
        "\n",
        "# Add the fifth and sixth convolutional layers with 128 filters\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the third max pooling layer and increase dropout rate to 0.4\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.4))\n",
        "\n",
        "# Add the seventh and eighth convolutional layers with 256 filters\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Add the fourth max pooling layer and increase dropout rate to 0.5\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.5))\n",
        "\n",
        "# Flatten the tensor output from the previous layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with softmax activation function for outputting class probabilities\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGLIUaxBQNpV",
        "papermill": {
          "duration": 0.024595,
          "end_time": "2023-08-18T05:25:09.907409",
          "exception": false,
          "start_time": "2023-08-18T05:25:09.882814",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's display the detailed architecture of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T07:20:05.344643Z",
          "iopub.status.busy": "2023-08-19T07:20:05.343977Z",
          "iopub.status.idle": "2023-08-19T07:20:05.408036Z",
          "shell.execute_reply": "2023-08-19T07:20:05.407175Z",
          "shell.execute_reply.started": "2023-08-19T07:20:05.344605Z"
        },
        "id": "tvUp2-KqQNpV",
        "papermill": {
          "duration": 0.15224,
          "end_time": "2023-08-18T05:25:10.08137",
          "exception": false,
          "start_time": "2023-08-18T05:25:09.92913",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YsHdbB3QNpV",
        "papermill": {
          "duration": 0.02853,
          "end_time": "2023-08-18T05:25:10.137084",
          "exception": false,
          "start_time": "2023-08-18T05:25:10.108554",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Our model consists of __1,186,346 parameters__, of which 1,184,426 are trainable. This is __a relatively compact model__, especially when compared to advanced architectures which often have tens or even hundreds of millions of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJmpHcb5QNpV",
        "papermill": {
          "duration": 0.032244,
          "end_time": "2023-08-18T05:25:10.196993",
          "exception": false,
          "start_time": "2023-08-18T05:25:10.164749",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 5 Training the CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kFKi0jUQNpV",
        "papermill": {
          "duration": 0.047807,
          "end_time": "2023-08-18T05:25:10.292531",
          "exception": false,
          "start_time": "2023-08-18T05:25:10.244724",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The training uses a batch size of 64 and will run for a maximum of 250 epochs or until the early stopping condition is met. During the training, the model's performance is evaluated on the validation data after each epoch. I've added a couple of callback functions to enhance the training process:\n",
        "\n",
        "* The __ReduceLROnPlateau callback__ is used to reduce the learning rate by half (factor=0.5) whenever the validation loss does not improve for 10 consecutive epochs. This helps to adjust the learning rate dynamically, allowing the model to get closer to the global minimum of the loss function when progress has plateaued. This strategy can improve the convergence of the training process.\n",
        "    \n",
        "\n",
        "* The __EarlyStopping callback__ is employed to monitor the validation loss and halt the training process when there hasn't been any improvement for a certain number of epochs, ensuring that the model doesn't waste computational resources and time. Furthermore, this callback restores the best weights from the training process, ensuring we conclude with the optimal model configuration from the epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-08-19T07:20:05.409525Z",
          "iopub.status.busy": "2023-08-19T07:20:05.409205Z",
          "iopub.status.idle": "2023-08-19T12:21:29.143695Z",
          "shell.execute_reply": "2023-08-19T12:21:29.142191Z",
          "shell.execute_reply.started": "2023-08-19T07:20:05.409494Z"
        },
        "id": "q1tkM0CAQNpV",
        "papermill": {
          "duration": 12929.399898,
          "end_time": "2023-08-18T09:00:39.722406",
          "exception": false,
          "start_time": "2023-08-18T05:25:10.322508",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set the batch size for the training\n",
        "batch_size = 64\n",
        "\n",
        "# Set the maximum number of epochs for the training\n",
        "epochs = 300\n",
        "\n",
        "# Define the optimizer (Adam)\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "\n",
        "# Compile the model with the defined optimizer, loss function, and metrics\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Add ReduceLROnPlateau callback\n",
        "# Here, the learning rate will be reduced by half (factor=0.5) if no improvement in validation loss is observed for 10 epochs\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "\n",
        "# Add EarlyStopping callback\n",
        "# Here, training will be stopped if no improvement in validation loss is observed for 40 epochs.\n",
        "# The `restore_best_weights` parameter ensures that the model weights are reset to the values from the epoch\n",
        "# with the best value of the monitored quantity (in this case, 'val_loss').\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Fit the model on the training data, using the defined batch size and number of epochs\n",
        "# The validation data is used to evaluate the model's performance during training\n",
        "# The callbacks implemented are learning rate reduction when a plateau is reached in validation loss and\n",
        "# stopping training early if no improvement is observed\n",
        "model.fit(data_generator.flow(X_train, y_train, batch_size=batch_size),\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          callbacks=[reduce_lr, early_stopping],\n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5zAdy1OQNpW",
        "papermill": {
          "duration": 0.053664,
          "end_time": "2023-08-18T09:00:39.890023",
          "exception": false,
          "start_time": "2023-08-18T09:00:39.836359",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 6 Visualizing the Learning Curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hulSI65sQNpW",
        "papermill": {
          "duration": 0.052121,
          "end_time": "2023-08-18T09:00:39.995025",
          "exception": false,
          "start_time": "2023-08-18T09:00:39.942904",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Generate plots for visualizing the training and validation loss, and accuracy evolution over epochs using model history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:29.147058Z",
          "iopub.status.busy": "2023-08-19T12:21:29.146318Z",
          "iopub.status.idle": "2023-08-19T12:21:29.698919Z",
          "shell.execute_reply": "2023-08-19T12:21:29.698018Z",
          "shell.execute_reply.started": "2023-08-19T12:21:29.14702Z"
        },
        "id": "2C8NdwmuQNpW",
        "papermill": {
          "duration": 27.620236,
          "end_time": "2023-08-18T09:01:07.67548",
          "exception": false,
          "start_time": "2023-08-18T09:00:40.055244",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model.history.history['loss'], label='Train Loss', color='#8502d1')\n",
        "plt.plot(model.history.history['val_loss'], label='Validation Loss', color='darkorange')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "# Plotting the training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model.history.history['accuracy'], label='Train Accuracy', color='#8502d1')\n",
        "plt.plot(model.history.history['val_accuracy'], label='Validation Accuracy', color='darkorange')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIjRxJ_AQNpW",
        "papermill": {
          "duration": 0.055602,
          "end_time": "2023-08-18T09:01:07.787039",
          "exception": false,
          "start_time": "2023-08-18T09:01:07.731437",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Based on the visualizations above, it's evident that the model is performing well without signs of overfitting. This conclusion is supported by the close alignment of training and validation accuracy and loss values throughout the training process. The gap between training and validation accuracy remains minimal, indicating that the model generalizes well to unseen data. Similarly, the model's loss on validation data closely follows the training loss, reinforcing the assertion of good generalization. Therefore, the model appears to be well regularized and not overfitting to the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_-pgJ_3QNpW",
        "papermill": {
          "duration": 0.05413,
          "end_time": "2023-08-18T09:01:07.895709",
          "exception": false,
          "start_time": "2023-08-18T09:01:07.841579",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 7 Evaluating the Optimal Model on Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk-NrSZ_QNpW",
        "papermill": {
          "duration": 0.054231,
          "end_time": "2023-08-18T09:01:08.004551",
          "exception": false,
          "start_time": "2023-08-18T09:01:07.95032",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "As we have set `restore_best_weights=True` in EarlyStopping, after training, the model itself will have the best weights Following this, I will use this model to evaluate its performance on the test data, calculating the test accuracy and loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:29.701115Z",
          "iopub.status.busy": "2023-08-19T12:21:29.700477Z",
          "iopub.status.idle": "2023-08-19T12:21:32.657065Z",
          "shell.execute_reply": "2023-08-19T12:21:32.655918Z",
          "shell.execute_reply.started": "2023-08-19T12:21:29.70108Z"
        },
        "id": "eTUC2pbKQNpX",
        "papermill": {
          "duration": 2.237538,
          "end_time": "2023-08-18T09:01:10.300746",
          "exception": false,
          "start_time": "2023-08-18T09:01:08.063208",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Use the model to make predictions, evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print('\\nTest Accuracy:', test_acc)\n",
        "print('Test Loss:    ', test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dijXC2BnQNpX",
        "papermill": {
          "duration": 0.057432,
          "end_time": "2023-08-18T09:01:10.41811",
          "exception": false,
          "start_time": "2023-08-18T09:01:10.360678",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "With a test accuracy of __more than 90%__, our model demonstrates exceptional performance on unseen data. This high accuracy, achieved using __a relatively compact model of just about 1.2 million parameters__, is noteworthy. Many advanced architectures employ tens or even hundreds of millions of parameters to achieve similar or only slightly better results. The proximity of the test loss and accuracy to their respective training counterparts signifies that our model is not merely memorizing the training data but is genuinely understanding patterns and effectively generalizing from the training data to unseen data. Thus, it can be inferred that our model not only delivers reliable predictions but also strikes a balance between efficiency and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW5Zu8n9QNpX",
        "papermill": {
          "duration": 0.058761,
          "end_time": "2023-08-18T09:01:10.534951",
          "exception": false,
          "start_time": "2023-08-18T09:01:10.47619",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 8 Performance on an Out-of-Dataset Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKdS82P7QNpX",
        "papermill": {
          "duration": 0.057631,
          "end_time": "2023-08-18T09:01:10.648722",
          "exception": false,
          "start_time": "2023-08-18T09:01:10.591091",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "To further explore the generalization capability of our trained CIFAR-10 classification model, we can assess its performance using an external truck image. This image, which isn't part of the CIFAR-10 dataset, has been sourced from [this GitHub repository](https://github.com/FarzadNekouee/Keras-CIFAR10-CNN-Model/blob/master/truck_sample.png)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:32.659223Z",
          "iopub.status.busy": "2023-08-19T12:21:32.658666Z",
          "iopub.status.idle": "2023-08-19T12:21:32.905315Z",
          "shell.execute_reply": "2023-08-19T12:21:32.904318Z",
          "shell.execute_reply.started": "2023-08-19T12:21:32.659189Z"
        },
        "id": "BUoERIQfQNpX",
        "papermill": {
          "duration": 0.297114,
          "end_time": "2023-08-18T09:01:11.003458",
          "exception": false,
          "start_time": "2023-08-18T09:01:10.706344",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Fetch the raw image from GitHub\n",
        "url = \"https://raw.githubusercontent.com/FarzadNekouee/Keras-CIFAR10-CNN-Model/master/truck_sample.png\"\n",
        "resp = urllib.request.urlopen(url)\n",
        "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "image = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "# Convert the image from BGR to RGB\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRz7q1hnQNpX",
        "papermill": {
          "duration": 0.056836,
          "end_time": "2023-08-18T09:01:11.119752",
          "exception": false,
          "start_time": "2023-08-18T09:01:11.062916",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Let's see our desired image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:32.907366Z",
          "iopub.status.busy": "2023-08-19T12:21:32.906819Z",
          "iopub.status.idle": "2023-08-19T12:21:33.19879Z",
          "shell.execute_reply": "2023-08-19T12:21:33.197884Z",
          "shell.execute_reply.started": "2023-08-19T12:21:32.907331Z"
        },
        "id": "JyYzG2NfQNpY",
        "papermill": {
          "duration": 0.310929,
          "end_time": "2023-08-18T09:01:11.488072",
          "exception": false,
          "start_time": "2023-08-18T09:01:11.177143",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAlYImUDQNpY",
        "papermill": {
          "duration": 0.064381,
          "end_time": "2023-08-18T09:01:11.619433",
          "exception": false,
          "start_time": "2023-08-18T09:01:11.555052",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "   We need to preprocess it in the same way as we did with the training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:33.201122Z",
          "iopub.status.busy": "2023-08-19T12:21:33.200085Z",
          "iopub.status.idle": "2023-08-19T12:21:33.210651Z",
          "shell.execute_reply": "2023-08-19T12:21:33.209505Z",
          "shell.execute_reply.started": "2023-08-19T12:21:33.201086Z"
        },
        "id": "i2WfV00xQNpY",
        "papermill": {
          "duration": 0.075603,
          "end_time": "2023-08-18T09:01:11.761355",
          "exception": false,
          "start_time": "2023-08-18T09:01:11.685752",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Resize it to 32x32 pixels\n",
        "image = cv2.resize(image, (32,32))\n",
        "\n",
        "# Normalize the image\n",
        "image = (image-mean)/(std+1e-7)\n",
        "\n",
        "# Add an extra dimension because the model expects a batch of images\n",
        "image = image.reshape((1, 32, 32, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbnE3DvQNpY",
        "papermill": {
          "duration": 0.062515,
          "end_time": "2023-08-18T09:01:11.888757",
          "exception": false,
          "start_time": "2023-08-18T09:01:11.826242",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Make the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:33.213178Z",
          "iopub.status.busy": "2023-08-19T12:21:33.212722Z",
          "iopub.status.idle": "2023-08-19T12:21:33.734941Z",
          "shell.execute_reply": "2023-08-19T12:21:33.733953Z",
          "shell.execute_reply.started": "2023-08-19T12:21:33.213121Z"
        },
        "id": "6yIcX33_QNpY",
        "papermill": {
          "duration": 0.599095,
          "end_time": "2023-08-18T09:01:12.55028",
          "exception": false,
          "start_time": "2023-08-18T09:01:11.951185",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZmWXkrDQNpY",
        "papermill": {
          "duration": 0.063343,
          "end_time": "2023-08-18T09:01:12.682259",
          "exception": false,
          "start_time": "2023-08-18T09:01:12.618916",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "   The prediction will be a 10-element probability vector. To get the predicted class, we find the index with the maximum value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-19T12:21:33.736933Z",
          "iopub.status.busy": "2023-08-19T12:21:33.736516Z",
          "iopub.status.idle": "2023-08-19T12:21:33.743699Z",
          "shell.execute_reply": "2023-08-19T12:21:33.742438Z",
          "shell.execute_reply.started": "2023-08-19T12:21:33.736896Z"
        },
        "id": "0k2ss7iDQNpZ",
        "papermill": {
          "duration": 0.075911,
          "end_time": "2023-08-18T09:01:12.823013",
          "exception": false,
          "start_time": "2023-08-18T09:01:12.747102",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": [
        "predicted_class = prediction.argmax()\n",
        "\n",
        "print('Predicted class: ', class_names[predicted_class])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CIFAR-10 Image Classification with CNN",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
