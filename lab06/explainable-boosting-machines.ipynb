{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":28007,"databundleVersionId":2425957,"sourceType":"competition"}],"dockerImageVersionId":30096,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n    <h1>Explainable Boosting machines for Tabular data</h1>\n    <h2>Interpretable or Accurate? Why Not Both?</h2>\n    \n</center>","metadata":{"execution":{"iopub.status.busy":"2021-07-26T04:20:49.093547Z","iopub.execute_input":"2021-07-26T04:20:49.094244Z","iopub.status.idle":"2021-07-26T04:20:49.104344Z","shell.execute_reply.started":"2021-07-26T04:20:49.09415Z","shell.execute_reply":"2021-07-26T04:20:49.102971Z"}}},{"cell_type":"markdown","source":"\n\n<p style=\"text-align:center;\"><img src=\"https://imgur.com/vYz7PYw.png\" alt=\"Dashboard\" width=\"800\" height=\"400\"></p>\n\n<center>A dashboard showing the performance comparison of various regressors in InterpretMl</center>\n","metadata":{}},{"cell_type":"markdown","source":"As summed up by [Miller](https://arxiv.org/abs/1706.07269), interpretability refers to the degree to which a human can understand the cause of a decision. Lately, there has been a lot of emphasis on creating inherently interpretable models and doing away from their black box counterparts. EBMs or [Explainable Boosting Machine](https://www.youtube.com/watch?v=MREiHgHgl0k),are models designed to have accuracy comparable to state-of-the-art machine learning methods like Random Forest and Boosted Trees while being highly intelligible and explainable. In this notebook, we will look at the idea behind EBMs and implement them for the given problem via [InterpretML](https://arxiv.org/pdf/1909.09223.pdf), a Unified Framework for Machine Learning Interpretability.\n\nThis notebook is an extension of an article I wrote on the same topic, which you would find useful : [Interpretable or Accurate? Why Not Both?](https://towardsdatascience.com/interpretable-or-accurate-why-not-both-4d9c73512192?sk=2f44377541a2f49939c921e54eb3cde7)\n\n---","metadata":{}},{"cell_type":"markdown","source":"## What are EBMs?\n\nEBM is a type of [generalized additive mode](https://projecteuclid.org/journals/statistical-science/volume-1/issue-3/Generalized-Additive-Models/10.1214/ss/1177013604.full)l or GAM for short. Linear models assume a linear relationship between the response and predictors. Thus, they are unable to capture the non-linearities in the data.\n\nLinear Model: y = β0 + β1x1 + β2x2 + … + βn xn\n\nTo overcome this shortcoming, in the late 80’s statisticians [Hastie & Tibshirani developed generalized additive models](https://projecteuclid.org/journals/statistical-science/volume-1/issue-3/Generalized-Additive-Models/10.1214/ss/1177013604.full)(GAMs), which keep the additive structure, and therefore the interpretability of the linear models. Thus, the linear relationship between the response and predictor variable gets [replaced by several non-linear smooth functions](https://datascienceplus.com/generalized-additive-models/)(f1, f2, etc.) to model and capture the non-linearities in the data. GAMs are more accurate than simple linear models, and since they do not contain any interactions between features, users can also easily interpret them.\n\nAdditive Model: y = f1(x1) + f2(x2) + … + fn(xn)\n\nEBMs are an improvement on the GAMs utilizing techniques like gradient boosting and bagging. EBMs include pairwise interaction terms, which increases their accuracy even further.\n\nEBMs: y = Ʃi fi (xi) + Ʃij fij(xi , xj) + Ʃijk fijk (xi , xj , xk )\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"## IntepretML: A Unified Framework for Machine Learning Interpretability\n\nEBMs come packaged within a Machine Learning Interpretability toolkit called [InterpretML](https://arxiv.org/pdf/1909.09223.pdf). It is an open-source package for training interpretable models as well as explaining black-box systems. Within InterpretML, the explainability algorithms are organized into two major sections, i.e., **Glassbox models** and **Blackbox explanations**. This means that this tool can not only explain the decisions of inherently interpretable models but also provide possible reasoning for black-box models. The following code architecture from the [official paper](https://arxiv.org/pdf/1909.09223.pdf) sums it nicely.\n\n![code architecture from the official paper | Source: [InterpretML: A Unified Framework for Machine Learning Interpretability](https://arxiv.org/pdf/1909.09223.pdf)](https://cdn-images-1.medium.com/max/2030/1*MxM1QHK31w16F9U0d5t7CQ.png)","metadata":{}},{"cell_type":"markdown","source":"To showcase EBM's properties, we'll first train a model using only the `target_carbon_monoxide` as the target column. However, later we will use all the other target columns to create our final submission.","metadata":{}},{"cell_type":"code","source":"#Installation\n!pip install interpret -q","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:23:34.597224Z","iopub.execute_input":"2021-07-03T03:23:34.597583Z","iopub.status.idle":"2021-07-03T03:24:02.248405Z","shell.execute_reply.started":"2021-07-03T03:23:34.597507Z","shell.execute_reply":"2021-07-03T03:24:02.247342Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Importing the necessary libraries and data\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\n#interpretml \nfrom interpret import show\nfrom interpret.data import Marginal\nfrom interpret.glassbox import ExplainableBoostingRegressor, LinearRegression, RegressionTree\n\nseed = 1\ntrain = pd.read_csv('../input/tabular-playground-series-jul-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-jul-2021/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:24:18.299464Z","iopub.execute_input":"2021-07-03T03:24:18.300054Z","iopub.status.idle":"2021-07-03T03:24:18.34043Z","shell.execute_reply.started":"2021-07-03T03:24:18.300013Z","shell.execute_reply":"2021-07-03T03:24:18.33942Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:24:21.659048Z","iopub.execute_input":"2021-07-03T03:24:21.659329Z","iopub.status.idle":"2021-07-03T03:24:21.696073Z","shell.execute_reply.started":"2021-07-03T03:24:21.659305Z","shell.execute_reply":"2021-07-03T03:24:21.694643Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Columns to be used for training:","metadata":{}},{"cell_type":"code","source":"columns = ['deg_C','relative_humidity','absolute_humidity','sensor_1','sensor_2','sensor_3','sensor_4','sensor_5']","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:24:26.389035Z","iopub.execute_input":"2021-07-03T03:24:26.389334Z","iopub.status.idle":"2021-07-03T03:24:26.393439Z","shell.execute_reply.started":"2021-07-03T03:24:26.389309Z","shell.execute_reply":"2021-07-03T03:24:26.392593Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target = 'target_carbon_monoxide'\nX_train, X_test, y_train, y_test = train_test_split(train[columns],train[target], test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:24:31.48968Z","iopub.execute_input":"2021-07-03T03:24:31.49004Z","iopub.status.idle":"2021-07-03T03:24:31.503626Z","shell.execute_reply.started":"2021-07-03T03:24:31.490012Z","shell.execute_reply":"2021-07-03T03:24:31.502719Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We'll first split our train datasets so that we can see how Interpretml can help us in the following:\n* Exploring the dataset\n* Train the Explainable Boosting Machine (EBM)\n* Understanding what the model learnt overall - Global Explanations\n* Understanding how an individual prediction was made - Local Explanations","metadata":{}},{"cell_type":"markdown","source":"## Exploring the dataset\n\nInterpret exposes a top-level method `show`, of which acts as the surface for rendering explanation visualizations. ","metadata":{}},{"cell_type":"code","source":"marginal = Marginal().explain_data(X_train, y_train, name = 'Train Data')\nshow(marginal)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:24:50.621071Z","iopub.execute_input":"2021-07-03T03:24:50.621385Z","iopub.status.idle":"2021-07-03T03:24:51.448481Z","shell.execute_reply.started":"2021-07-03T03:24:50.62135Z","shell.execute_reply":"2021-07-03T03:24:51.447634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Feel free to interact with the above visualisation and gain understanding of your data","metadata":{}},{"cell_type":"markdown","source":"## Training the Explainable Boosting Machine (EBM)","metadata":{}},{"cell_type":"code","source":"ebm = ExplainableBoostingRegressor(random_state=seed, n_jobs=-1)\nebm.fit(X_train, y_train) ","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:24:40.127074Z","iopub.execute_input":"2021-07-03T03:24:40.127459Z","iopub.status.idle":"2021-07-03T03:24:50.619548Z","shell.execute_reply.started":"2021-07-03T03:24:40.127429Z","shell.execute_reply":"2021-07-03T03:24:50.618489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Interpretability Approaches\n\n![](https://miro.medium.com/max/642/1*8ov3dWV39WHkx8SG6pMXWA.png)","metadata":{}},{"cell_type":"markdown","source":"## Global Explanations - explaining the entire model behavior.","metadata":{}},{"cell_type":"code","source":"ebm_global = ebm.explain_global(name='EBM')\nshow(ebm_global)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:25:13.051392Z","iopub.execute_input":"2021-07-03T03:25:13.051688Z","iopub.status.idle":"2021-07-03T03:25:13.67858Z","shell.execute_reply.started":"2021-07-03T03:25:13.051662Z","shell.execute_reply":"2021-07-03T03:25:13.677731Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Local Explanations: explaining individual predictions","metadata":{}},{"cell_type":"code","source":"ebm_local = ebm.explain_local(X_test[:5], y_test[:5], name='EBM')\nshow(ebm_local)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:25:18.500307Z","iopub.execute_input":"2021-07-03T03:25:18.500826Z","iopub.status.idle":"2021-07-03T03:25:18.539279Z","shell.execute_reply.started":"2021-07-03T03:25:18.50079Z","shell.execute_reply":"2021-07-03T03:25:18.538427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluating EBM performance on the hold out dataset","metadata":{}},{"cell_type":"code","source":"from interpret.perf import RegressionPerf\n\nebm_perf = RegressionPerf(ebm.predict).explain_perf(X_test, y_test, name='EBM')\nshow(ebm_perf)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:25:26.478817Z","iopub.execute_input":"2021-07-03T03:25:26.47931Z","iopub.status.idle":"2021-07-03T03:25:26.505643Z","shell.execute_reply.started":"2021-07-03T03:25:26.479273Z","shell.execute_reply":"2021-07-03T03:25:26.504726Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comparing EBM performance with other Regressors - Linear Regression, RegressionTree and Random Forest\n\nInterpret gives us the ability to compare the performance of multiple models in a single dashboard","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression(random_state=seed)\nlr.fit(X_train, y_train)\n\nrt = RegressionTree(random_state=seed)\nrt.fit(X_train, y_train)\n\nrf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:25:29.804036Z","iopub.execute_input":"2021-07-03T03:25:29.804499Z","iopub.status.idle":"2021-07-03T03:25:31.352491Z","shell.execute_reply.started":"2021-07-03T03:25:29.804411Z","shell.execute_reply":"2021-07-03T03:25:31.350944Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_perf = RegressionPerf(lr.predict).explain_perf(X_test, y_test, name='Linear Regression')\nrt_perf = RegressionPerf(rt.predict).explain_perf(X_test, y_test, name='Regression Tree')\nrf_perf = RegressionPerf(rf.predict).explain_perf(X_test, y_test, name='Blackbox')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:25:33.064811Z","iopub.execute_input":"2021-07-03T03:25:33.065208Z","iopub.status.idle":"2021-07-03T03:25:33.300615Z","shell.execute_reply.started":"2021-07-03T03:25:33.065176Z","shell.execute_reply":"2021-07-03T03:25:33.29985Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_global = lr.explain_global(name='Linear Regression')\nrt_global = rt.explain_global(name='Regression Tree')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:25:36.023633Z","iopub.execute_input":"2021-07-03T03:25:36.023992Z","iopub.status.idle":"2021-07-03T03:25:36.029315Z","shell.execute_reply.started":"2021-07-03T03:25:36.023963Z","shell.execute_reply":"2021-07-03T03:25:36.028428Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comparing Performances of different models","metadata":{}},{"cell_type":"code","source":"show(lr_perf)\nshow(rt_perf)\nshow(ebm_perf)\nshow(rf_perf)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:27:57.972136Z","iopub.execute_input":"2021-07-03T03:27:57.972511Z","iopub.status.idle":"2021-07-03T03:27:58.010183Z","shell.execute_reply.started":"2021-07-03T03:27:57.972474Z","shell.execute_reply":"2021-07-03T03:27:58.009041Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TPS Competition\n## Creating multiple predictions and merging them in a common submission file","metadata":{}},{"cell_type":"markdown","source":"Now that we have an idea about the working of EBMs, let's calculate the predictions for different target columns i.e `target_benzene`, `target_carbon_monoxide` and `target_nitrogen_oxides`.","metadata":{}},{"cell_type":"code","source":"def predictions(target_column):\n    \"\"\"\n    Function to calculate EBM predictions based on the target column specified\n    \n    \"\"\"\n    training_set = train[columns]\n    target = train[target_column]\n    ebm = ExplainableBoostingRegressor(n_jobs=-1)\n    ebm.fit(training_set,target)\n    preds = ebm.predict(test[columns])\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:36:36.028334Z","iopub.execute_input":"2021-07-03T03:36:36.028645Z","iopub.status.idle":"2021-07-03T03:36:36.034278Z","shell.execute_reply.started":"2021-07-03T03:36:36.028621Z","shell.execute_reply":"2021-07-03T03:36:36.032794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds_benzene = predictions('target_benzene')\npreds_carbon_monoxide = predictions('target_carbon_monoxide')\npreds_nitrogen_oxides = predictions('target_nitrogen_oxides')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:36:59.767574Z","iopub.execute_input":"2021-07-03T03:36:59.767899Z","iopub.status.idle":"2021-07-03T03:37:32.185604Z","shell.execute_reply.started":"2021-07-03T03:36:59.767874Z","shell.execute_reply":"2021-07-03T03:37:32.184532Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'date_time': test.date_time,\n    'target_carbon_monoxide': preds_carbon_monoxide,\n    'target_benzene': preds_benzene,\n    'target_nitrogen_oxides': preds_nitrogen_oxides\n})\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:37:33.402621Z","iopub.execute_input":"2021-07-03T03:37:33.403034Z","iopub.status.idle":"2021-07-03T03:37:33.417941Z","shell.execute_reply.started":"2021-07-03T03:37:33.402989Z","shell.execute_reply":"2021-07-03T03:37:33.417057Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T03:38:01.33685Z","iopub.execute_input":"2021-07-03T03:38:01.337154Z","iopub.status.idle":"2021-07-03T03:38:01.354597Z","shell.execute_reply.started":"2021-07-03T03:38:01.337129Z","shell.execute_reply":"2021-07-03T03:38:01.353417Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}